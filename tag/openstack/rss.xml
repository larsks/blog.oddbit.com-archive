<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>openstack on The Odd Bit</title>
    <link>https://blog.oddbit.com/tag/openstack/</link>
    <description>Recent content in openstack on The Odd Bit</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://blog.oddbit.com/tag/openstack/rss.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>OVN and DHCP: A minimal example</title>
      <link>https://blog.oddbit.com/post/2019-12-19-ovn-and-dhcp/</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2019-12-19-ovn-and-dhcp/</guid>
      <description>Introduction A long time ago, I wrote an article all about OpenStack Neutron (which at that time was called Quantum). That served as an excellent reference for a number of years, but if you&#39;ve deployed a recent version of OpenStack you may have noticed that the network architecture looks completely different. The network namespaces previously used to implement routers and dhcp servers are gone (along with iptables rules and other features), and have been replaced by OVN (&amp;ldquo;Open Virtual Network&amp;rdquo;).</description>
    </item>
    
    <item>
      <title>Running Keystone with Docker Compose</title>
      <link>https://blog.oddbit.com/post/2019-06-07-running-keystone-with-docker-c/</link>
      <pubDate>Fri, 07 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2019-06-07-running-keystone-with-docker-c/</guid>
      <description>In this article, we will look at what is necessary to run OpenStack&#39;s Keystone service (and the requisite database server) in containers using Docker Compose.
Running MariaDB The standard mariadb docker image can be configured via a number of environment variables. It also benefits from persistent volume storage, since in most situations you don&#39;t want to lose your data when you remove a container. A simple docker command line for starting MariaDB might look something like:</description>
    </item>
    
    <item>
      <title>Grouping aggregation queries in Gnocchi 4.0.x</title>
      <link>https://blog.oddbit.com/post/2018-02-26-grouping-aggregation-queries-i/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2018-02-26-grouping-aggregation-queries-i/</guid>
      <description>In this article, we&#39;re going to ask Gnocchi (the OpenStack telemetry storage service) how much memory was used, on average, over the course of each day by each project in an OpenStack environment.
Environment I&#39;m working with an OpenStack &amp;ldquo;Pike&amp;rdquo; deployment, which means I have Gnocchi 4.0.x. More recent versions of Gnocchi (4.1.x and later) have a new aggregation API called dynamic aggregates, but that isn&#39;t available in 4.0.x so in this article we&#39;ll be using the legacy /v1/aggregations API.</description>
    </item>
    
    <item>
      <title>Safely restarting an OpenStack server with Ansible</title>
      <link>https://blog.oddbit.com/post/2018-01-24-safely-restarting-an-openstack-server-wi/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2018-01-24-safely-restarting-an-openstack-server-wi/</guid>
      <description>The other day on #ansible, someone was looking for a way to safely shut down a Nova server, wait for it to stop, and then start it up again using the openstack cli. The first part seemed easy:
- hosts: myserver tasks: - name: shut down the server command: poweroff become: true  &amp;hellip;but that will actually fail with the following result:
TASK [shut down server] ************************************* fatal: [myserver]: UNREACHABLE! =&amp;gt; {&amp;quot;changed&amp;quot;: false, &amp;quot;msg&amp;quot;: &amp;quot;Failed to connect to the host via ssh: Shared connection to 10.</description>
    </item>
    
    <item>
      <title>Ansible for Infrastructure Testing</title>
      <link>https://blog.oddbit.com/post/2017-08-02-ansible-for-infrastructure-testing/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2017-08-02-ansible-for-infrastructure-testing/</guid>
      <description>At $JOB we often find ourselves at customer sites where we see the same set of basic problems that we have previously encountered elsewhere (&amp;ldquo;your clocks aren&#39;t in sync&amp;rdquo; or &amp;ldquo;your filesystem is full&amp;rdquo; or &amp;ldquo;you haven&#39;t installed a critical update&amp;rdquo;, etc). We would like a simple tool that could be run either by the customer or by our own engineers to test for and report on these common issues. Fundamentally, we want something that acts like a typical code test suite, but for infrastructure.</description>
    </item>
    
    <item>
      <title>OpenStack, Containers, and Logging</title>
      <link>https://blog.oddbit.com/post/2017-06-14-openstack-containers-and-logging/</link>
      <pubDate>Wed, 14 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2017-06-14-openstack-containers-and-logging/</guid>
      <description>I&#39;ve been thinking about logging in the context of OpenStack and containerized service deployments. I&#39;d like to lay out some of my thoughts on this topic and see if people think I am talking crazy or not.
There are effectively three different mechanisms that an application can use to emit log messages:
 Via some logging-specific API, such as the legacy syslog API By writing a byte stream to stdout/stderr By writing a byte stream to a file  A substantial advantage to the first mechanism (using a logging API) is that the application is logging messages rather than bytes.</description>
    </item>
    
    <item>
      <title>Making sure your Gerrit changes aren&#39;t broken</title>
      <link>https://blog.oddbit.com/post/2017-01-22-making-sure-your-gerrit-changes-aren-t-b/</link>
      <pubDate>Sun, 22 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2017-01-22-making-sure-your-gerrit-changes-aren-t-b/</guid>
      <description>It&#39;s a bit of an embarrassment when you submit a review to Gerrit only to have it fail CI checks immediately because of something as simple as a syntax error or pep8 failure that you should have caught yourself before submitting&amp;hellip;but you forgot to run your validations before submitting the change.
In many cases you can alleviate this through the use of the git pre-commit hook, which will run every time you commit changes locally.</description>
    </item>
    
    <item>
      <title>Exploring YAQL Expressions</title>
      <link>https://blog.oddbit.com/post/2016-08-11-exploring-yaql-expressions/</link>
      <pubDate>Thu, 11 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2016-08-11-exploring-yaql-expressions/</guid>
      <description>The Newton release of Heat adds support for a yaql intrinsic function, which allows you to evaluate yaql expressions in your Heat templates. Unfortunately, the existing yaql documentation is somewhat limited, and does not offer examples of many of yaql&#39;s more advanced features.
I am working on a Fluentd composable service for TripleO. I want to allow each service to specify a logging source configuration fragment, for example:
parameters: NovaAPILoggingSource: type: json description: Fluentd logging configuration for nova-api.</description>
    </item>
    
    <item>
      <title>Connecting another vm to your tripleo-quickstart deployment</title>
      <link>https://blog.oddbit.com/post/2016-05-19-connecting-another-vm-to-your-tripleo-qu/</link>
      <pubDate>Thu, 19 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2016-05-19-connecting-another-vm-to-your-tripleo-qu/</guid>
      <description>Let&#39;s say that you have set up an environment using tripleo-quickstart and you would like to add another virtual machine to the mix that has both &amp;ldquo;external&amp;rdquo; connectivity (&amp;ldquo;external&amp;rdquo; in quotes because I am using it in the same way as the quickstart does w/r/t the undercloud) and connectivity to the overcloud nodes. How would you go about setting that up?
For a concrete example, let&#39;s presume you have deployed an environment using the default tripleo-quickstart configuration, which looks like this:</description>
    </item>
    
    <item>
      <title>Deploying an HA OpenStack development environment with tripleo-quickstart
</title>
      <link>https://blog.oddbit.com/post/2016-02-19-deploy-an-ha-openstack-development-envir/</link>
      <pubDate>Fri, 19 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2016-02-19-deploy-an-ha-openstack-development-envir/</guid>
      <description>In this article I would like to introduce tripleo-quickstart, a tool that will automatically provision a virtual environment and then use TripleO to deploy an HA OpenStack on top of it.
Introducing Tripleo-Quickstart The goal of the Tripleo-Quickstart project is to replace the instack-virt-setup tool for quickly setting up virtual TripleO environments, and to ultimately become the tool used by both developers and upstream CI for this purpose. The project is a set of Ansible playbooks that will take care of:</description>
    </item>
    
    <item>
      <title>Ansible 2.0: New OpenStack modules</title>
      <link>https://blog.oddbit.com/post/2015-10-26-ansible-20-new-openstack-modules/</link>
      <pubDate>Mon, 26 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-10-26-ansible-20-new-openstack-modules/</guid>
      <description>This is the second in a loose sequence of articles looking at new features in Ansible 2.0. In the previous article I looked at the Docker connection driver. In this article, I would like to provide an overview of the new-and-much-improved suite of modules for interacting with an OpenStack environment, and provide a few examples of their use.
In versions of Ansible prior to 2.0, there was a small collection of OpenStack modules.</description>
    </item>
    
    <item>
      <title>Migrating Cinder volumes between OpenStack environments using shared NFS storage</title>
      <link>https://blog.oddbit.com/post/2015-09-29-migrating-cinder-volumes-between-openstack-environments/</link>
      <pubDate>Tue, 29 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-09-29-migrating-cinder-volumes-between-openstack-environments/</guid>
      <description>Many of the upgrade guides for OpenStack focus on in-place upgrades to your OpenStack environment. Some organizations may opt for a less risky (but more hardware intensive) option of setting up a parallel environment, and then migrating data into the new environment. In this article, we look at how to use Cinder backups with a shared NFS volume to facilitate the migration of Cinder volumes between two different OpenStack environments.</description>
    </item>
    
    <item>
      <title>Provider external networks (in an appropriate amount of detail)</title>
      <link>https://blog.oddbit.com/post/2015-08-13-provider-external-networks-details/</link>
      <pubDate>Thu, 13 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-08-13-provider-external-networks-details/</guid>
      <description>In Quantum in Too Much Detail, I discussed the architecture of a Neutron deployment in detail. Since that article was published, Neutron gained the ability to handle multiple external networks with a single L3 agent. While I wrote about that back in 2014, I covered the configuration side of it in much more detail than I discussed the underlying network architecture. This post addresses the architecture side.
The players This document describes the architecture that results from a particular OpenStack configuration, specifically:</description>
    </item>
    
    <item>
      <title>In which we are amazed it doesn&#39;t all fall apart</title>
      <link>https://blog.oddbit.com/post/2015-07-26-in-which-we-are-amazed-it-doesnt-all-fall-apart/</link>
      <pubDate>Sun, 26 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-07-26-in-which-we-are-amazed-it-doesnt-all-fall-apart/</guid>
      <description>So, the Kilo release notes say:
nova-manage migrate-flavor-data  But nova-manage says:
nova-manage db migrate_flavor_data  But that says:
Missing arguments: max_number  And the help says:
usage: nova-manage db migrate_flavor_data [-h] [--max-number &amp;lt;number&amp;gt;]  Which indicates that &amp;ndash;max-number is optional, but whatever, so you try:
nova-manage db migrate_flavor_data --max-number 100  And that says:
Missing arguments: max_number  So just for kicks you try:
nova-manage db migrate_flavor_data --max_number 100  And that says:</description>
    </item>
    
    <item>
      <title>OpenStack Networking without DHCP</title>
      <link>https://blog.oddbit.com/post/2015-06-26-openstack-networking-without-dhcp/</link>
      <pubDate>Fri, 26 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-06-26-openstack-networking-without-dhcp/</guid>
      <description>In an OpenStack environment, cloud-init generally fetches information from the metadata service provided by Nova. It also has support for reading this information from a configuration drive, which under OpenStack means a virtual CD-ROM device attached to your instance containing the same information that would normally be available via the metadata service.
It is possible to generate your network configuration from this configuration drive, rather than relying on the DHCP server provided by your OpenStack environment.</description>
    </item>
    
    <item>
      <title>Heat-kubernetes Demo with Autoscaling</title>
      <link>https://blog.oddbit.com/post/2015-06-19-heatkubernetes-demo-with-autoscaling/</link>
      <pubDate>Fri, 19 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-06-19-heatkubernetes-demo-with-autoscaling/</guid>
      <description>Next week is the Red Hat Summit in Boston, and I&#39;ll be taking part in a Project Atomic presentation in which I will discuss various (well, two) options for deploying Atomic into an OpenStack environment, focusing on my heat-kubernetes templates.
As part of that presentation, I&#39;ve put together a short demonstration video:
 This shows off the autoscaling behavior available with recent versions of these templates (and also serves as a very brief introduction to working with Kubernetes).</description>
    </item>
    
    <item>
      <title>Diagnosing problems with an OpenStack deployment</title>
      <link>https://blog.oddbit.com/post/2015-03-09-diagnosing-problems-with-an-openstack-deplo/</link>
      <pubDate>Mon, 09 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-03-09-diagnosing-problems-with-an-openstack-deplo/</guid>
      <description>I recently had the chance to help a colleague debug some problems in his OpenStack installation. The environment was unique because it was booting virtualized aarch64 instances, which at the time did not have any PCI bus support&amp;hellip;which in turn precluded things like graphic consoles (i.e., VNC or SPICE consoles) for the Nova instances.
This post began life as an email summarizing the various configuration changes we made on the systems to get things up and running.</description>
    </item>
    
    <item>
      <title>Installing nova-docker with devstack</title>
      <link>https://blog.oddbit.com/post/2015-02-11-installing-novadocker-with-devstack/</link>
      <pubDate>Wed, 11 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-02-11-installing-novadocker-with-devstack/</guid>
      <description>This is a long-form response to this question, and describes how to get the nova-docker driver up running with devstack under Ubuntu 14.04 (Trusty). I wrote a similar post for Fedora 21, although that one was using the RDO Juno packages, while this one is using devstack and the upstream sources.
Getting started We&#39;ll be using the Ubuntu 14.04 cloud image (because my test environment runs on OpenStack).
First, let&#39;s install a few prerequisites:</description>
    </item>
    
    <item>
      <title>Installing nova-docker on Fedora 21/RDO Juno</title>
      <link>https://blog.oddbit.com/post/2015-02-06-installing-nova-docker-on-fedora-21/</link>
      <pubDate>Fri, 06 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-02-06-installing-nova-docker-on-fedora-21/</guid>
      <description>This post comes about indirectly by a request on IRC in #rdo for help getting nova-docker installed on Fedora 21. I ran through the process from start to finish and decided to write everything down for posterity.
Getting started I started with the Fedora 21 Cloud Image, because I&#39;m installing onto OpenStack and the cloud images include some features that are useful in this environment.
We&#39;ll be using OpenStack packages from the RDO Juno repository.</description>
    </item>
    
    <item>
      <title>Filtering libvirt XML in Nova</title>
      <link>https://blog.oddbit.com/post/2015-02-05-filtering-libvirt-xml-in-nova/</link>
      <pubDate>Thu, 05 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-02-05-filtering-libvirt-xml-in-nova/</guid>
      <description>I saw a request from a customer float by the other day regarding the ability to filter the XML used to create Nova instances in libvirt. The customer effectively wanted to blacklist a variety of devices (and device types). The consensus seems to be &amp;ldquo;you can&#39;t do this right now and upstream is unlikely to accept patches that implement this behavior&amp;rdquo;, but it sounded like an interesting problem, so&amp;hellip;
 https://github.</description>
    </item>
    
    <item>
      <title>Running nova-libvirt and nova-docker on the same host</title>
      <link>https://blog.oddbit.com/post/2015-01-17-running-novalibvirt-and-novadocker-on-the-same-host/</link>
      <pubDate>Sat, 17 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-01-17-running-novalibvirt-and-novadocker-on-the-same-host/</guid>
      <description>I regularly use OpenStack on my laptop with libvirt as my hypervisor. I was interested in experimenting with recent versions of the nova-docker driver, but I didn&#39;t have a spare system available on which to run the driver, and I use my regular nova-compute service often enough that I didn&#39;t want to simply disable it temporarily in favor of nova-docker.
 NB As pointed out by gustavo in the comments, running two neutron-openvswitch-agents on the same host &amp;ndash; as suggested in this article &amp;ndash; is going to lead to nothing but sadness and doom.</description>
    </item>
    
    <item>
      <title>Accessing the serial console of your Nova servers</title>
      <link>https://blog.oddbit.com/post/2014-12-22-accessing-the-serial-console-of-your-nova-servers/</link>
      <pubDate>Mon, 22 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-12-22-accessing-the-serial-console-of-your-nova-servers/</guid>
      <description>One of the new features available in the Juno release of OpenStack is support for serial console access to your Nova servers. This post looks into how to configure the serial console feature and then how to access the serial consoles of your Nova servers.
Configuring serial console support In previous release of OpenStack, read-only access to the serial console of your servers was available through the os-getConsoleOutput server action (exposed via nova console-log on the command line).</description>
    </item>
    
    <item>
      <title>Cloud-init and the case of the changing hostname</title>
      <link>https://blog.oddbit.com/post/2014-12-10-cloudinit-and-the-case-of-the-changing-hostname/</link>
      <pubDate>Wed, 10 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-12-10-cloudinit-and-the-case-of-the-changing-hostname/</guid>
      <description>Setting the stage I ran into a problem earlier this week deploying RDO Icehouse under RHEL 6. My target systems were a set of libvirt guests deployed from the RHEL 6 KVM guest image, which includes cloud-init in order to support automatic configuration in cloud environments. I take advantage of this when using libvirt by attaching a configuration drive so that I can pass in ssh keys and a user-data script.</description>
    </item>
    
    <item>
      <title>Fedora Atomic, OpenStack, and Kubernetes (oh my)</title>
      <link>https://blog.oddbit.com/post/2014-11-24-fedora-atomic-openstack-and-kubernetes-oh-my/</link>
      <pubDate>Mon, 24 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-11-24-fedora-atomic-openstack-and-kubernetes-oh-my/</guid>
      <description>While experimenting with Fedora Atomic, I was looking for an elegant way to automatically deploy Atomic into an OpenStack environment and then automatically schedule some Docker containers on the Atomic host. This post describes my solution.
Like many other cloud-targeted distributions, Fedora Atomic runs cloud-init when the system boots. We can take advantage of this to configure the system at first boot by providing a user-data blob to Nova when we boot the instance.</description>
    </item>
    
    <item>
      <title>Creating a Windows image for OpenStack</title>
      <link>https://blog.oddbit.com/post/2014-11-15-creating-a-windows-image-for-openstack/</link>
      <pubDate>Sat, 15 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-11-15-creating-a-windows-image-for-openstack/</guid>
      <description>If you want to build a Windows image for use in your OpenStack environment, you can follow the example in the official documentation, or you can grab a Windows 2012r2 evaluation pre-built image from the nice folks at CloudBase.
The CloudBase-provided image is built using a set of scripts and configuration files that CloudBase has made available on GitHub.
The CloudBase repository is an excellent source of information, but I wanted to understand the process myself.</description>
    </item>
    
    <item>
      <title>Integrating custom code with Nova using hooks</title>
      <link>https://blog.oddbit.com/post/2014-09-27-integrating-custom-code-with-n/</link>
      <pubDate>Sat, 27 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-09-27-integrating-custom-code-with-n/</guid>
      <description>Would you like to run some custom Python code when Nova creates and destroys virtual instances on your compute hosts? This is possible using Nova&#39;s support for hooks, but the existing documentation is somewhat short on examples, so I&#39;ve spent some time trying to get things working.
The demo_nova_hooks repository contains a working example of the techniques discussed in this article.
What&#39;s a hook? A Nova &amp;ldquo;hook&amp;rdquo; is a mechanism that allows you to attach a class of your own design to a particular function or method call in Nova.</description>
    </item>
    
    <item>
      <title>Heat Hangout</title>
      <link>https://blog.oddbit.com/post/2014-09-05-heat-hangout/</link>
      <pubDate>Fri, 05 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-09-05-heat-hangout/</guid>
      <description>I ran a Google Hangout this morning on Deploying with Heat. You can find the slides for the presentation on line here, and the Heat templates (as well as slide sources) are available on github.
If you have any questions about the presentation, please feel free to ping me on irc (larsks).
 </description>
    </item>
    
    <item>
      <title>Visualizing Heat stacks</title>
      <link>https://blog.oddbit.com/post/2014-09-02-visualizing-heat-stacks/</link>
      <pubDate>Tue, 02 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-09-02-visualizing-heat-stacks/</guid>
      <description>I spent some time today learning about Heat autoscaling groups, which are incredibly nifty but a little opaque from the Heat command line, since commands such as heat resource-list don&#39;t recurse into nested stacks. It is possible to introspect these resources (you can pass the physical resource id of a nested stack to heat resource-list, for example)&amp;hellip;
&amp;hellip;but I really like visualizing things, so I wrote a quick hack called dotstack that will generate dot language output from a Heat stack.</description>
    </item>
    
    <item>
      <title>Docker plugin bugs</title>
      <link>https://blog.oddbit.com/post/2014-09-01-docker-plugin-bugs/</link>
      <pubDate>Mon, 01 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-09-01-docker-plugin-bugs/</guid>
      <description>This is a companion to my article on the Docker plugin for Heat.
While writing that article, I encountered a number of bugs in the Docker plugin and elsewhere. I&#39;ve submitted patches for most of the issues I encountered:
Bugs in the Heat plugin   https://bugs.launchpad.net/heat/+bug/1364017
docker plugin fails to delete a container resource in CREATE_FAILED state.
  https://bugs.launchpad.net/heat/+bug/1364041
docker plugin volumes_from parameter should be a list.
  https://bugs.</description>
    </item>
    
    <item>
      <title>Annotated documentation for DockerInc::Docker::Container</title>
      <link>https://blog.oddbit.com/post/2014-08-31-docker-contain-doc/</link>
      <pubDate>Sat, 30 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-08-31-docker-contain-doc/</guid>
      <description>This is a companion to my article on the Docker plugin for Heat.
DockerInc::Docker::Container Properties   cmd : List
Command to run after spawning the container.
Optional property.
Example:
 cmd: [ &#39;thttpd&#39;, &#39;-C&#39;, &#39;/etc/thttpd.conf&#39;, &#39;-D&#39;, &#39;-c&#39;, &#39;*.cgi&#39;]    dns : List
Set custom DNS servers.
Example:
 dns: - 8.8.8.8 - 8.8.4.4    docker_endopint : String
Docker daemon endpoint. By default the local Docker daemon will be used.</description>
    </item>
    
    <item>
      <title>Docker plugin for OpenStack Heat</title>
      <link>https://blog.oddbit.com/post/2014-08-30-docker-plugin-for-openstack-he/</link>
      <pubDate>Sat, 30 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-08-30-docker-plugin-for-openstack-he/</guid>
      <description>I have been looking at both Docker and OpenStack recently. In my last post I talked a little about the Docker driver for Nova; in this post I&#39;ll be taking an in-depth look at the Docker plugin for Heat, which has been available since the Icehouse release but is surprisingly under-documented.
The release announcement on the Docker blog includes an example Heat template, but it is unfortunately grossly inaccurate and has led many people astray.</description>
    </item>
    
    <item>
      <title>Using wait conditions with Heat</title>
      <link>https://blog.oddbit.com/post/2014-08-30-using-wait-conditions-with-hea/</link>
      <pubDate>Sat, 30 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-08-30-using-wait-conditions-with-hea/</guid>
      <description>This post accompanies my article on the Docker plugin for Heat.
In order for WaitCondition resources to operate correctly in Heat, you will need to make sure that that you have:
 Created the necessary Heat domain and administrative user in Keystone, Configured appropriate values in heat.conf for stack_user_domain, stack_domain_admin, and stack_domain_admin_password. Configured an appropriate value in heat.conf for heat_waitcondition_server_url. On a single-system install this will often be pointed by default at 127.</description>
    </item>
    
    <item>
      <title>nova-docker and environment variables</title>
      <link>https://blog.oddbit.com/post/2014-08-28-novadocker-and-environment-var/</link>
      <pubDate>Thu, 28 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-08-28-novadocker-and-environment-var/</guid>
      <description>I&#39;ve been playing with Docker a bit recently, and decided to take a look at the nova-docker driver for OpenStack.
The nova-docker driver lets Nova, the OpenStack Compute service, spawn Docker containers instead of hypervisor-based servers. For certain workloads, this leads to better resource utilization than you would get with a hypervisor-based solution, while at the same time givin you better support for multi-tenancy and flexible networking than you get with Docker by itself.</description>
    </item>
    
    <item>
      <title>Booting an instance with multiple fixed addresses</title>
      <link>https://blog.oddbit.com/post/2014-05-28-booting-an-instance-with-multi/</link>
      <pubDate>Wed, 28 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-05-28-booting-an-instance-with-multi/</guid>
      <description>This article expands on my answer to Add multiple specific IPs to instance, a question posted to ask.openstack.org.
In order to serve out SSL services from an OpenStack instance, you will generally want one local ip address for each SSL virtual host you support. It is possible to create an instance with multiple fixed addresses, but there are a few complications to watch out for.
Assumptions This article assumes that the following resources exist:</description>
    </item>
    
    <item>
      <title>Multiple external networks with a single L3 agent</title>
      <link>https://blog.oddbit.com/post/2014-05-28-multiple-external-networks-wit/</link>
      <pubDate>Wed, 28 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-05-28-multiple-external-networks-wit/</guid>
      <description>In the old days (so, like, last year), Neutron supported a single external network per L3 agent. You would run something like this&amp;hellip;
$ neutron net-create external --router:external=true  &amp;hellip;and neutron would map this to the bridge defined in external_network_bridge in /etc/neutron/l3_agent.ini. If you wanted to support more than a single external network, you would need to run multiple L3 agents, each with a unique value for external_network_bridge.
There is now a better option available.</description>
    </item>
    
    <item>
      <title>Video: Configuring OpenStack&#39;s external bridge on a single-interface system</title>
      <link>https://blog.oddbit.com/post/2014-05-27-configuring-openstacks-externa/</link>
      <pubDate>Tue, 27 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-05-27-configuring-openstacks-externa/</guid>
      <description>I&#39;ve just put a video on Youtube that looks at the steps required to set up the external bridge (br-ex) on a single-interface system:
 </description>
    </item>
    
    <item>
      <title>Open vSwitch and persistent MAC addresses</title>
      <link>https://blog.oddbit.com/post/2014-05-23-open-vswitch-and-persistent-ma/</link>
      <pubDate>Fri, 23 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-05-23-open-vswitch-and-persistent-ma/</guid>
      <description>Normally I like to post solutions, but today&#39;s post is about a vexing problem to which I have not been able to find a solution.
This started as a simple attempt to set up external connectivity on an all-in-one Icehouse install deployed on an OpenStack instance. I wanted to add eth0 to br-ex in order to model a typical method for providing external connectivity, but I ran into a very odd problem: the system would boot and work fine for a few seconds, but would then promptly lose network connectivity.</description>
    </item>
    
    <item>
      <title>Solved: Open vSwitch and persistent MAC addresses</title>
      <link>https://blog.oddbit.com/post/2014-05-23-solved-open-vswitch-and-persis/</link>
      <pubDate>Fri, 23 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-05-23-solved-open-vswitch-and-persis/</guid>
      <description>In my previous post I discussed a problem I was having setting a persistent MAC address on an OVS bridge device. It looks like the short answer is, &amp;ldquo;don&#39;t use ip link set ...&amp;rdquo; for this purpose.
You can set the bridge MAC address via ovs-vsctl like this:
ovs-vsctl set bridge br-ex other-config:hwaddr=$MACADDR  So I&#39;ve updated my ifconfig-br-ex to look like this:
DEVICE=br-ex DEVICETYPE=ovs TYPE=OVSBridge ONBOOT=yes OVSBOOTPROTO=dhcp OVSDHCPINTERFACES=eth0 MACADDR=fa:16:3e:ef:91:ec OVS_EXTRA=&amp;quot;set bridge br-ex other-config:hwaddr=$MACADDR&amp;quot;  The OVS_EXTRA parameter gets passed to the add-br call like this:</description>
    </item>
    
    <item>
      <title>Fedora and OVS Bridge Interfaces</title>
      <link>https://blog.oddbit.com/post/2014-05-20-fedora-and-ovs-bridge-interfac/</link>
      <pubDate>Tue, 20 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-05-20-fedora-and-ovs-bridge-interfac/</guid>
      <description>I run OpenStack on my laptop, and I&#39;ve been chasing down a pernicious problem with OVS bridge interfaces under both F19 and F20. My OpenStack environment relies on an OVS bridge device named br-ex for external connectivity and for making services available to OpenStack instances, but after rebooting, br-ex was consistently unconfigured, which caused a variety of problems.
This is the network configuration file for br-ex on my system:
DEVICE=br-ex DEVICETYPE=ovs TYPE=OVSBridge BOOTPROT=static IPADDR=192.</description>
    </item>
    
    <item>
      <title>Firewalld, NetworkManager, and OpenStack</title>
      <link>https://blog.oddbit.com/post/2014-05-20-firewalld-and-openstack/</link>
      <pubDate>Tue, 20 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-05-20-firewalld-and-openstack/</guid>
      <description>These are my notes on making OpenStack play well with firewalld and NetworkManager.
NetworkManager By default, NetworkManager attempts to start a DHCP client on every new available interface. Since booting a single instance in OpenStack can result in the creation of several virtual interfaces, this results in a lot of:
May 19 11:58:24 pk115wp-lkellogg NetworkManager[1357]: &amp;lt;info&amp;gt; Activation (qvb512640bd-ee) starting connection &#39;Wired connection 2&#39;  You can disable this behavior by adding the following to /etc/NetworkManager/NetworkManager.</description>
    </item>
    
    <item>
      <title>Flat networks with ML2 and OpenVSwitch</title>
      <link>https://blog.oddbit.com/post/2014-05-19-flat-networks-with-ml-and-open/</link>
      <pubDate>Mon, 19 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-05-19-flat-networks-with-ml-and-open/</guid>
      <description>Due to an unfortunate incident involving sleep mode and an overheated backpack I had the &amp;ldquo;opportunity&amp;rdquo; to rebuild my laptop. Since this meant reinstalling OpenStack I used this as an excuse to finally move to the ML2 network plugin for Neutron.
I was attempting to add an external network using the normal incantation:
neutron net-create external -- --router:external=true \ --provider:network_type=flat \ --provider:physical_network=physnet1  While this command completed successfully, I was left without any connectivity between br-int and br-ex, despite having in my /etc/neutron/plugins/ml2/ml2_conf.</description>
    </item>
    
    <item>
      <title>Multinode OpenStack with Packstack</title>
      <link>https://blog.oddbit.com/post/2014-02-27-multinode/</link>
      <pubDate>Thu, 27 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-02-27-multinode/</guid>
      <description>I was the presenter for this morning&#39;s RDO hangout, where I ran through a simple demonstration of setting up a multinode OpenStack deployment using packstack.
The slides are online here.
Here&#39;s the video (also available on the event page):
 </description>
    </item>
    
    <item>
      <title>Show OVS external-ids</title>
      <link>https://blog.oddbit.com/post/2014-01-19-show-ovs-externalids/</link>
      <pubDate>Sun, 19 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-01-19-show-ovs-externalids/</guid>
      <description>This is just here as a reminder for me:
An OVS interface has a variety of attributes associated with it, including an external-id field that can be used to associate resources outside of OpenVSwitch with the interface. You can view this field with the following command:
$ ovs-vsctl --columns=name,external-ids list Interface  Which on my system, with a single virtual instance, looks like this:
# ovs-vsctl --columns=name,external-ids list Interface . .</description>
    </item>
    
    <item>
      <title>Stupid OpenStack Tricks</title>
      <link>https://blog.oddbit.com/post/2014-01-16-stupid-openstack-tricks/</link>
      <pubDate>Thu, 16 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-01-16-stupid-openstack-tricks/</guid>
      <description>I work with several different OpenStack installations. I usually work on the command line, sourcing in an appropriate stackrc with credentials as necessary, but occasionally I want to use the dashboard for something.
For all of the deployments with which I work, the keystone endpoint is on the same host as the dashboard. So rather than trying to remember which dashboard url I want for the environment I&#39;m currently using on the command line, I put together this shell script:</description>
    </item>
    
    <item>
      <title>Direct access to Nova metadata</title>
      <link>https://blog.oddbit.com/post/2014-01-14-direct-access-to-nova-metadata/</link>
      <pubDate>Tue, 14 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-01-14-direct-access-to-nova-metadata/</guid>
      <description>When you boot a virtual instance under OpenStack, your instance has access to certain instance metadata via the Nova metadata service, which is canonically available at http://169.254.169.254/.
In an environment running Neutron, a request from your instance must traverse a number of steps:
 From the instance to a router, Through a NAT rule in the router namespace, To an instance of the neutron-ns-metadata-proxy, To the actual Nova metadata service  When there are problem accessing the metadata, it can be helpful to verify that the metadata service itself is configured correctly and returning meaningful information.</description>
    </item>
    
    <item>
      <title>RDO Bug Triage</title>
      <link>https://blog.oddbit.com/post/2014-01-13-rdo-bug-triage/</link>
      <pubDate>Mon, 13 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-01-13-rdo-bug-triage/</guid>
      <description>This Wednesday, January 15, at 14:00 UTC (that&#39;s 9AM US/Eastern, or date -d &amp;quot;14:00 UTC&amp;quot; in your local timezone) I will be helping out with the RDO bug triage day. We&#39;ll be trying to validate all the untriaged bugs opened against RDO.
Feel free to drop by on #rdo and help out or ask questions.</description>
    </item>
    
    <item>
      <title>Visualizing Neutron Networking with GraphViz</title>
      <link>https://blog.oddbit.com/post/2013-12-23-visualizing-network-with-graphviz/</link>
      <pubDate>Mon, 23 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2013-12-23-visualizing-network-with-graphviz/</guid>
      <description>I&#39;ve put together a few tools to help gather information about your Neutron and network configuration and visualize it in different ways. All of these tools are available as part of my neutron-diag repository on GitHub.
In this post I&#39;m going to look at a tool that will help you visualize the connectivity of network devices on your system.
mk-network-dot There are a lot of devices involved in your Neutron network configuration.</description>
    </item>
    
    <item>
      <title>An introduction to OpenStack Heat</title>
      <link>https://blog.oddbit.com/post/2013-12-06-an-introduction-to-openstack-heat/</link>
      <pubDate>Fri, 06 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2013-12-06-an-introduction-to-openstack-heat/</guid>
      <description>Heat is a template-based orchestration mechanism for use with OpenStack. With Heat, you can deploy collections of resources &amp;ndash; networks, servers, storage, and more &amp;ndash; all from a single, parameterized template.
In this article I will introduce Heat templates and the heat command line client.
Writing templates Because Heat began life as an analog of AWS CloudFormation, it supports the template formats used by the CloudFormation (CFN) tools. It also supports its own native template format, called HOT (&amp;ldquo;Heat Orchestration Templates&amp;rdquo;).</description>
    </item>
    
    <item>
      <title>A unified CLI for OpenStack</title>
      <link>https://blog.oddbit.com/post/2013-11-22-a-unified-cli-for-op/</link>
      <pubDate>Fri, 22 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2013-11-22-a-unified-cli-for-op/</guid>
      <description>The python-openstackclient project, by Dean Troyer and others, is a new command line tool to replace the existing command line clients (including commands such as nova, keystone, cinder, etc).
This tool solves two problems I&#39;ve encountered in the past:
  Command line options between different command line clients are sometimes inconsistent.
  The output from the legacy command line tools is not designed to be machine parse-able (and yet people do it anyway).</description>
    </item>
    
    <item>
      <title>json-tools: cli for generating and filtering json</title>
      <link>https://blog.oddbit.com/post/2013-11-17-json-tools/</link>
      <pubDate>Sun, 17 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2013-11-17-json-tools/</guid>
      <description>Interacting with JSON-based APIs from the command line can be difficult, and OpenStack is filled with REST APIs that consume or produce JSON. I&#39;ve just put pair of tools for generating and filtering JSON on the command line, called collectively json-tools.
Both make use of the Python dpath module to populate or filter JSON objects.
The jsong command generates JSON on stdout. You provide /-delimited paths on the command line to represent the JSON structure.</description>
    </item>
    
    <item>
      <title>Quantum in Too Much Detail</title>
      <link>https://blog.oddbit.com/post/2013-11-14-quantum-in-too-much-detail/</link>
      <pubDate>Thu, 14 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2013-11-14-quantum-in-too-much-detail/</guid>
      <description>I originally posted this article on the RDO website.
 The players This document describes the architecture that results from a particular OpenStack configuration, specifically:
 Quantum networking using GRE tunnels; A dedicated network controller; A single instance running on a compute host  Much of the document will be relevant to other configurations, but details will vary based on your choice of layer 2 connectivity, number of running instances, and so forth.</description>
    </item>
    
    <item>
      <title>A random collection of OpenStack Tools</title>
      <link>https://blog.oddbit.com/post/2013-11-12-a-random-collection/</link>
      <pubDate>Tue, 12 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2013-11-12-a-random-collection/</guid>
      <description>I&#39;ve been working with OpenStack a lot recently, and I&#39;ve ended up with a small collection of utilities that make my life easier. On the odd chance that they&#39;ll make your life easier, too, I thought I&#39;d hilight them here.
Crux Crux is a tool for provisioning tenants, users, and roles in keystone. Instead of a sequence of keystone command, you can provision new tenants, users, and roles with a single comand.</description>
    </item>
    
    <item>
      <title>Why does the Neutron documentation recommend three interfaces?</title>
      <link>https://blog.oddbit.com/post/2013-10-28-why-does-the-neutron/</link>
      <pubDate>Mon, 28 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2013-10-28-why-does-the-neutron/</guid>
      <description>The documentation for configuring Neutron recommends that a network controller has three physical interfaces:
 Before you start, set up a machine to be a dedicated network node. Dedicated network nodes should have the following NICs: the management NIC (called MGMT_INTERFACE), the data NIC (called DATA_INTERFACE), and the external NIC (called EXTERNAL_INTERFACE).
 People occasionally ask, &amp;ldquo;why three interfaces? What if I only have two?&amp;quot;, so I wanted to provide an extended answer that might help people understand what the interfaces are for and what trade-offs are involved in using fewer interfaces.</description>
    </item>
    
    <item>
      <title>Automatic configuration of Windows instances in OpenStack, part 1</title>
      <link>https://blog.oddbit.com/post/2012-11-04-openstack-windows-config-part1/</link>
      <pubDate>Sun, 04 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2012-11-04-openstack-windows-config-part1/</guid>
      <description>This is the first of two articles in which I discuss my work in getting some Windows instances up and running in our OpenStack environment. This article is primarily about problems I encountered along the way.
Motivations Like many organizations, we have a mix of Linux and Windows in our environment. Some folks in my group felt that it would be nice to let our Windows admins take advantage of OpenStack for prototyping and sandboxing in the same ways our Linux admins can use it.</description>
    </item>
    
    <item>
      <title>Chasing OpenStack idle connection timeouts</title>
      <link>https://blog.oddbit.com/post/2012-07-30-openstack-idle-connection-timeouts/</link>
      <pubDate>Mon, 30 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2012-07-30-openstack-idle-connection-timeouts/</guid>
      <description>The original problem I&#39;ve recently spent some time working on an OpenStack deployment. I ran into a problem in which the compute service would frequently stop communicating with the AMQP message broker (qpidd).
In order to gather some data on the problem, I ran the following simple test:
 Wait n minutes Run nova boot ... to create an instance Wait a minute and see if the new instance becomes ACTIVE If it works, delete the instance, set n = 2n and repeat  This demonstrated that communication was failing after about an hour, which correlates rather nicely with the idle connection timeout on the firewall.</description>
    </item>
    
  </channel>
</rss>