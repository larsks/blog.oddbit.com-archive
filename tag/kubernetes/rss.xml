<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kubernetes on The Odd Bit</title>
    <link>https://blog.oddbit.com/tag/kubernetes/</link>
    <description>Recent content in kubernetes on The Odd Bit</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.oddbit.com/tag/kubernetes/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Connecting OpenShift to an External Ceph Cluster</title>
      <link>https://blog.oddbit.com/post/2021-08-23-external-ocs/</link>
      <pubDate>Mon, 23 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2021-08-23-external-ocs/</guid>
      <description>Red Hat&amp;rsquo;s [OpenShift Data Foundation][ocs] (formerly &amp;ldquo;OpenShift Container Storage&amp;rdquo;, or &amp;ldquo;OCS&amp;rdquo;) allows you to either (a) automatically set up a Ceph cluster as an application running on your OpenShift cluster, or (b) connect your OpenShift cluster to an externally managed Ceph cluster. While setting up Ceph as an OpenShift application is a relatively polished experienced, connecting to an external cluster still has some rough edges.
NB I am not a Ceph expert.</description>
    </item>
    
    <item>
      <title>Getting started with KSOPS</title>
      <link>https://blog.oddbit.com/post/2021-03-09-getting-started-with-ksops/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2021-03-09-getting-started-with-ksops/</guid>
      <description>Kustomize is a tool for assembling Kubernetes manifests from a collection of files. We&amp;rsquo;re making extensive use of Kustomize in the operate-first project. In order to keep secrets stored in our configuration repositories, we&amp;rsquo;re using the KSOPS plugin, which enables Kustomize to use sops to encrypt/files using GPG.
In this post, I&amp;rsquo;d like to walk through the steps necessary to get everything up and running.
Set up GPG We encrypt files using GPG, so the first step is making sure that you have a GPG keypair and that your public key is published where other people can find it.</description>
    </item>
    
    <item>
      <title>Object storage with OpenShift Container Storage</title>
      <link>https://blog.oddbit.com/post/2021-02-10-object-storage-with-openshift/</link>
      <pubDate>Wed, 10 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2021-02-10-object-storage-with-openshift/</guid>
      <description>OpenShift Container Storage (OCS) from Red Hat deploys Ceph in your OpenShift cluster (or allows you to integrate with an external Ceph cluster). In addition to the file- and block- based volume services provided by Ceph, OCS includes two S3-api compatible object storage implementations.
The first option is the Ceph Object Gateway (radosgw), Ceph&amp;rsquo;s native object storage interface. The second option called the &amp;ldquo;Multicloud Object Gateway&amp;rdquo;, which is in fact a piece of software named Noobaa, a storage abstraction layer that was acquired by Red Hat in 2018.</description>
    </item>
    
    <item>
      <title>Heat-kubernetes Demo with Autoscaling</title>
      <link>https://blog.oddbit.com/post/2015-06-19-heatkubernetes-demo-with-autos/</link>
      <pubDate>Fri, 19 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-06-19-heatkubernetes-demo-with-autos/</guid>
      <description>Next week is the Red Hat Summit in Boston, and I&amp;rsquo;ll be taking part in a Project Atomic presentation in which I will discuss various (well, two) options for deploying Atomic into an OpenStack environment, focusing on my heat-kubernetes templates.
As part of that presentation, I&amp;rsquo;ve put together a short demonstration video:
 This shows off the autoscaling behavior available with recent versions of these templates (and also serves as a very brief introduction to working with Kubernetes).</description>
    </item>
    
    <item>
      <title>External networking for Kubernetes services</title>
      <link>https://blog.oddbit.com/post/2015-02-10-external-networking-for-kubern/</link>
      <pubDate>Tue, 10 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-02-10-external-networking-for-kubern/</guid>
      <description>I have recently started running some &amp;ldquo;real&amp;rdquo; services (that is, &amp;ldquo;services being consumed by someone other than myself&amp;rdquo;) on top of Kubernetes (running on bare metal), which means I suddenly had to confront the question of how to provide external access to Kubernetes hosted services. Kubernetes provides two solutions to this problem, neither of which is particularly attractive out of the box:
  There is a field createExternalLoadBalancer that can be set in a service description.</description>
    </item>
    
    <item>
      <title>Building a minimal web server for testing Kubernetes</title>
      <link>https://blog.oddbit.com/post/2015-01-04-building-a-minimal-web-server/</link>
      <pubDate>Sun, 04 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2015-01-04-building-a-minimal-web-server/</guid>
      <description>I have recently been doing some work with Kubernetes, and wanted to put together a minimal image with which I could test service and pod deployment. Size in this case was critical: I wanted something that would download quickly when initially deployed, because I am often setting up and tearing down Kubernetes as part of my testing (and some of my test environments have poor external bandwidth).
Building thttpd My go-to minimal webserver is thttpd.</description>
    </item>
    
    <item>
      <title>Fedora Atomic, OpenStack, and Kubernetes (oh my)</title>
      <link>https://blog.oddbit.com/post/2014-11-24-fedora-atomic-openstack-and-ku/</link>
      <pubDate>Mon, 24 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-11-24-fedora-atomic-openstack-and-ku/</guid>
      <description>While experimenting with Fedora Atomic, I was looking for an elegant way to automatically deploy Atomic into an OpenStack environment and then automatically schedule some Docker containers on the Atomic host. This post describes my solution.
Like many other cloud-targeted distributions, Fedora Atomic runs cloud-init when the system boots. We can take advantage of this to configure the system at first boot by providing a user-data blob to Nova when we boot the instance.</description>
    </item>
    
    <item>
      <title>Docker networking with dedicated network containers</title>
      <link>https://blog.oddbit.com/post/2014-10-06-docker-networking-with-dedicat/</link>
      <pubDate>Mon, 06 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2014-10-06-docker-networking-with-dedicat/</guid>
      <description>The current version of Docker has a very limited set of networking options:
 bridge &amp;ndash; connect a container to the Docker bridge host &amp;ndash; run the container in the global network namespace container:xxx &amp;ndash; connect a container to the network namespace of another container none &amp;ndash; do not configure any networking  If you need something more than that, you can use a tool like pipework to provision additional network interfaces inside the container, but this leads to a synchronization problem: pipework can only be used after your container is running.</description>
    </item>
    
  </channel>
</rss>
