<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>openshift on The Odd Bit</title>
    <link>https://blog.oddbit.com/tag/openshift/</link>
    <description>Recent content in openshift on The Odd Bit</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 29 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.oddbit.com/tag/openshift/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kubernetes External Secrets</title>
      <link>https://blog.oddbit.com/post/2021-08-29-kubernetes-external-secrets/</link>
      <pubDate>Sun, 29 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2021-08-29-kubernetes-external-secrets/</guid>
      <description>At $JOB we maintain the configuration for our OpenShift clusters in a public git repository. Changes in the git repository are applied automatically using ArgoCD and Kustomize. This works great, but the public nature of the repository means we need to find a secure solution for managing secrets (such as passwords and other credentials necessary for authenticating to external services). In particular, we need a solution that permits our public repository to be the source of truth for our cluster configuration, without compromising our credentials.</description>
    </item>
    
    <item>
      <title>Connecting OpenShift to an External Ceph Cluster</title>
      <link>https://blog.oddbit.com/post/2021-08-23-external-ocs/</link>
      <pubDate>Mon, 23 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2021-08-23-external-ocs/</guid>
      <description>Red Hat&amp;rsquo;s [OpenShift Data Foundation][ocs] (formerly &amp;ldquo;OpenShift Container Storage&amp;rdquo;, or &amp;ldquo;OCS&amp;rdquo;) allows you to either (a) automatically set up a Ceph cluster as an application running on your OpenShift cluster, or (b) connect your OpenShift cluster to an externally managed Ceph cluster. While setting up Ceph as an OpenShift application is a relatively polished experienced, connecting to an external cluster still has some rough edges.
NB I am not a Ceph expert.</description>
    </item>
    
    <item>
      <title>Getting started with KSOPS</title>
      <link>https://blog.oddbit.com/post/2021-03-09-getting-started-with-ksops/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2021-03-09-getting-started-with-ksops/</guid>
      <description>Kustomize is a tool for assembling Kubernetes manifests from a collection of files. We&amp;rsquo;re making extensive use of Kustomize in the operate-first project. In order to keep secrets stored in our configuration repositories, we&amp;rsquo;re using the KSOPS plugin, which enables Kustomize to use sops to encrypt/files using GPG.
In this post, I&amp;rsquo;d like to walk through the steps necessary to get everything up and running.
Set up GPG We encrypt files using GPG, so the first step is making sure that you have a GPG keypair and that your public key is published where other people can find it.</description>
    </item>
    
    <item>
      <title>Object storage with OpenShift Container Storage</title>
      <link>https://blog.oddbit.com/post/2021-02-10-object-storage-with-openshift/</link>
      <pubDate>Wed, 10 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2021-02-10-object-storage-with-openshift/</guid>
      <description>OpenShift Container Storage (OCS) from Red Hat deploys Ceph in your OpenShift cluster (or allows you to integrate with an external Ceph cluster). In addition to the file- and block- based volume services provided by Ceph, OCS includes two S3-api compatible object storage implementations.
The first option is the Ceph Object Gateway (radosgw), Ceph&amp;rsquo;s native object storage interface. The second option called the &amp;ldquo;Multicloud Object Gateway&amp;rdquo;, which is in fact a piece of software named Noobaa, a storage abstraction layer that was acquired by Red Hat in 2018.</description>
    </item>
    
    <item>
      <title>Installing metallb on OpenShift with Kustomize</title>
      <link>https://blog.oddbit.com/post/2020-09-27-installing-metallb-on-openshif/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2020-09-27-installing-metallb-on-openshif/</guid>
      <description>Out of the box, OpenShift (4.x) on bare metal doesn&amp;rsquo;t come with any integrated load balancer support (when installed in a cloud environment, OpenShift typically makes use of the load balancing features available from the cloud provider). Fortunately, there are third party solutions available that are designed to work in bare metal environments. MetalLB is a popular choice, but requires some minor fiddling to get it to run properly on OpenShift.</description>
    </item>
    
    <item>
      <title>OpenShift and CNV: MAC address management in CNV 2.4</title>
      <link>https://blog.oddbit.com/post/2020-08-10-mac-address-management-in-cnv/</link>
      <pubDate>Mon, 10 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2020-08-10-mac-address-management-in-cnv/</guid>
      <description>This is part of a series of posts about my experience working with OpenShift and CNV. In this post, I&amp;rsquo;ll look at how the recently released CNV 2.4 resolves some issues in managing virtual machines that are attached directly to local layer 2 networks
In an earlier post, I discussed some issues around the management of virtual machine MAC addresses in CNV 2.3: in particular, that virtual machines are assigned a random MAC address not just at creation time but every time they boot.</description>
    </item>
    
    <item>
      <title>OpenShift and CNV: Exposing virtualized services</title>
      <link>https://blog.oddbit.com/post/2020-07-30-openshift-and-cnv-part-2-expos/</link>
      <pubDate>Thu, 30 Jul 2020 01:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2020-07-30-openshift-and-cnv-part-2-expos/</guid>
      <description>This is the second in a series of posts about my experience working with OpenShift and CNV. In this post, I&amp;rsquo;ll be taking a look at how to expose services on a virtual machine once you&amp;rsquo;ve git it up and running.
 TL;DR Overview Connectivity options Direct attachment Using an OpenShift Service  Exposing services on NodePorts Exposing services on cluster external IPso Exposing services using a LoadBalancer     TL;DR Networking seems to be a weak area for CNV right now.</description>
    </item>
    
    <item>
      <title>OpenShift and CNV: Installer network requirements</title>
      <link>https://blog.oddbit.com/post/2020-07-30-openshift-and-cnv-part-1-worki/</link>
      <pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2020-07-30-openshift-and-cnv-part-1-worki/</guid>
      <description>This is the first in a series of posts about my experience working with OpenShift and CNV (&amp;ldquo;Container Native Virtualization&amp;rdquo;, a technology that allows you to use OpenShift to manage virtualized workloads in addition to the containerized workloads for which OpenShift is known). In this post, I&amp;rsquo;ll be taking a look at the installation experience, and in particular at how restrictions in our local environment interacted with the network requirements of the installer.</description>
    </item>
    
    <item>
      <title>Sockets on OpenShift</title>
      <link>https://blog.oddbit.com/post/2013-11-23-openshift-socket-pro/</link>
      <pubDate>Sat, 23 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.oddbit.com/post/2013-11-23-openshift-socket-pro/</guid>
      <description>In this article, a followup to my previous post regarding long-poll servers and Python, we investigate the code changes that were necessary to make the code work when deployed on OpenShift.
In the previous post, we implemented IO polling to watch for client disconnects at the same time we were waiting for messages on a message bus:
poll = zmq.Poller() poll.register(subsock, zmq.POLLIN) poll.register(rfile, zmq.POLLIN) events = dict(poll.poll()) . . .  If you were to try this at home, you would find that everything worked as described&amp;hellip;but if you were to deploy the same code to OpenShift, you would find that the problem we were trying to solve (the server holding file descriptors open after a client disconnected) would still exist.</description>
    </item>
    
  </channel>
</rss>
